---
title: 'Beyond the Field-of-View: Enhancing Scene Visibility and Perception with Clip-Recurrent Transformer'
date: 2024-06-26
permalink: /posts/2024/06/26/TIV
tags:
  - 自动驾驶
  - 计算成像
---

2024年6月，课题组博士研究生时昊、蒋奇、印晓婷、王泽等人的论文《Beyond the Field-of-View: Enhancing Scene Visibility and Perception with Clip-Recurrent Transformer》发表于T-IV期刊。

## 期刊介绍

IEEE Transactions on Intelligent Vehicles是IEEE旗下智能车辆领域顶级期刊，SCI、JCR一区，2023年影响因子14.0，去除自引影响因子8.4。该期刊在计算机科学/人工智能领域JCR综合排名5/197，在交通科学与技术领域JCR综合排名2/72。

## 论文主要图表
<div style="text-align:center">
<img src="/images/research/2024-06-26-TIV/图片1.png" alt="Portfolio"  style="width: 1024px">
</div>

## 论文介绍

本文中，我们提出了一种名为“FlowLens”的新型架构，首次通过在线视频补全技术扩展了自动驾驶车辆的视野范围，从而增强场景的可见性、感知力和系统安全性。

传统的视觉传感器由于硬件成本和系统尺寸的限制，其摄像头的视场往往受到限制，无法提供足够的覆盖范围。然而，从时空角度来看，我们可以通过分析过去的视频流来获取摄像头物理视场之外的信息。利用这一技术，FlowLens能够重构未被直接观察到的场景，提供可靠的语义上下文，甚至增强视野外的感知能力。

为了实现这一目标，FlowLens结合了显式的光流技术和隐式的剪辑循环变压器来传播特征。该架构具有两大特色：
<ol>
<li>剪辑循环中心: 配备了三维解耦交叉注意力（3D-Decoupled Cross Attention, DDCA），用以逐步处理随时间积累的全局信息。
</li>
<li>多分支混合融合前馈网络（Mix Fusion Feed Forward Network, MixF3N），以增强本地特征不同频率空间流动的细粒度融合与精确度。
</li>
</ol>

此外，我们利用经过各种视野掩膜处理的KITTI360数据集来促进训练和评估，覆盖了外部和内部视场扩展场景。通过对不同模型进行量化评估和质量比较，我们对视场外的语义和目标检测进行了深入研究。

通过广泛的实验和用户调研，包括在线和离线视频补全以及视场外感知任务，FlowLens证明了其在当前领域的领先性能。为了促进更广泛的学术交流和应用开发，我们已经将源代码和数据集公开。

这项工作不仅推动了自动驾驶技术的前沿发展，也为相关领域的研究人员和工程师提供了宝贵的资源和灵感。我们期待着该技术在未来的实际应用和进一步的研究探索。


## BibTeX
```tex
@article{shi2022beyond,
  title={Beyond the Field-of-View: Enhancing Scene Visibility and Perception with Clip-Recurrent Transformer},
  author={Shi, Hao and Jiang, Qi and Yang, Kailun and Yin, Xiaoting and Ni, Huajian and Wang, Kaiwei},
  journal={arXiv e-prints},
  pages={arXiv--2211},
  year={2022}
}
```

