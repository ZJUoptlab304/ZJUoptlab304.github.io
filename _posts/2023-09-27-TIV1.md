---
title: 'FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving'
date: 2023-09-27
permalink: /posts/2023/09/27/TIV1
tags:
  - 自动驾驶
  - 光流估计
---

2023年9月，课题组博士研究生易中华、时昊、蒋奇、王泽、叶耀祖等人的论文《FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving》发表于T-IV期刊。

## 期刊介绍

IEEE Transactions on Intelligent Vehicles是IEEE旗下智能车辆领域顶级期刊，SCI、JCR一区，2023年影响因子14.0，去除自引影响因子8.4。该期刊在计算机科学/人工智能领域JCR综合排名5/197，在交通科学与技术领域JCR综合排名2/72。

## 论文主要图表
<div style="text-align:center">
<img src="/images/research/2024-06-27-TIV1/图片1.png" alt="Portfolio"  style="max-width: 100%">
</div>
<div style="text-align:center">
<img src="/images/research/2024-06-27-TIV1/图片2.png" alt="Portfolio"  style="max-width: 100%">
</div>

## 论文介绍

本文中，我们提出了FocusFlow框架，用于解决光流估计框架在关键点位置处精度不足的问题。
先前的光流估计工作关注于提升全图的光流估计精度，但是在一些下游任务，如SLAM中，更关心的是图像中关键点的光流精度。为此，我们提出了FocusFlow，一种可以提升现有光流方法在关键点上的光流估计精度的通用性框架。其中心思想是：将关键点作为光流网络的提示，用于指导模型增加对于关键点位置的关注度，并且在模型监督时，也设计针对关键点位置光流估计的损失，从而避免模型无重点的学习。

具体而言，FocusFlow的贡献如下：
<ol>
<li>
提出了一种显式考虑关键点分布的建模方法。
</li>
<li>
提出了条件点控制损失（CPCL）和混合损失函数，用于在光流估计中关注于关键点的精度提升。
</li>
<li>
提出了一种条件控制的模型架构，其可以兼容现有的编码-解码架构的光流估计模型。
</li>
</ol>
经过在Sintel和KITTI上的测试，FocusFlow相比于原有的光流估计模型，能够在关键点位置获得巨大的光流估计精度提升。此外，我们验证了该架构对PWC-Net、RAFT、FlowFormer的兼容性和有效性，同时测试了在ORB、SIFT、GF（cv::goodFeaturesToTrack）以及SiLK等几种关键点上的结果，证明了FocusFlow的泛用性。

该工作服务于任何仅对特定位置光流精度有更高要求的任务，在SLAM、自动驾驶等领域具有很高的应用价值。此外，该方法提出的显式考虑点信息的建模方法，也对其他的稠密估计任务（如单目深度估计）有参考意义。我们希望该工作对后续的研究者能够有所启发，在该基础上发展出更有影响力的工作。


## 代码仓库
<a href="https://github.com/ZhonghuaYi/FocusFlow_official" target="_blank">Github<br></a>


## BibTeX
```tex
@article{yi2023focusflow,
  title={FocusFlow: Boosting Key-Points Optical Flow Estimation for Autonomous Driving},
  author={Yi, Zhonghua and Shi, Hao and Yang, Kailun and Jiang, Qi and Ye, Yaozu and Wang, Ze and Ni, Huajian and Wang, Kaiwei},
  journal={IEEE Transactions on Intelligent Vehicles},
  year={2023},
  publisher={IEEE}
}
```

